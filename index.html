<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Xiaojuan Qi, University of Hong Kong"> 
<meta name="description" content="Xiaojuan Qi's home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xiaojuan Qi</title>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body >

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Xiaojuan Qi &nbsp; <h1>
				</div>
                            
				<h3>Assistant Professor</h3>
				<p>
					Chow Yei Ching Building, Rm 518 </br>
					Dept. of Electrical and Electronic Engineering</br>
					University of Hong Kong </br>
					 Hong Kong</br>
					</br>
					Email: <a href="mailto:xjqi@eee.hku.hk">xjqi [at] eee.hku.hk</a><br>
                                    <h3><a href="xiaojuanqi.pdf">[Curriculum Vitae]</a> <a href="https://labhku.github.io/">[Our Lab]</a> <a href="https://labhku.github.io//people/">[Lab Members]</a><a href="https://github.com/CVMI-Lab">[Lab GitHub]</a><h3>
				</p>
				<!--<p>
					<a href="https://github.com/hszhao"><img src="pics/github.png" height="30px"></a>
					<a href="https://scholar.google.com/citations?user=4uE10I0AAAAJ&hl=en"><img src="pics/google_scholar.png" height="30px"></a>
					<a href="https://hk.linkedin.com/in/hengshuang-zhao-347b8391"><img src="pics/linkedin.png" height="30px"></a>
				</p>-->
			</td>
			<td>
				<!--<img src="pics/zhaohengshuang.jpg" border="0" width="240"></br>-->
				<img src="pics/cropped_img" border="0" width="240"></br>
			</td>
		<tr>
	</tbody>
</table>


<h2>Biography</h2>
<p>
	I am currently an assistant professor at <a href="https://www.hku.hk/">the University of Hong Kong</a> and a member of <a href="https://www.dvlab.ai/">Deep Vision Lab</a> . My research lies in the broad areas of Computer Vision, Deep Learning, and Artificial Intelligence. We aim at endowing machines with the capability to perceive, understand, and reconstruct the visual world with the following focuses: 1) developing label-efficient and computation-efficient deep learning algorithms for natural and medical image analysis; 2) designing effective techniques for 3D scene understanding and reconstruction; and 3) building lifelong learning machines that can learn continuously, transfer previous knowledge and discover novel concepts (through interaction).
  
</p>
I obtained my Ph.D. degree in <a href="http://www.cse.cuhk.edu.hk">Computer Science and Engineering Department</a>, <a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong (CUHK)</a>, supervised by <a href="http://www.cse.cuhk.edu.hk/~leojia">Prof. Jiaya Jia</a> in 2018. Before that, I got the B.Eng. degree in Electronic Science and Technology at <a href = "http://www.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a> supervised by <a href="http://ir.sjtu.edu.cn/~yazhang/">Prof. Ya Zhang</a> in 2014.
<p>
</p>
<font color = 'red'>Please do not hesitate to drop me an email if you are interested in joining my lab. </font>
<p>
</p>
<!--
<h2>Recent Updates</h2>
<ul>
<li>
<font color = 'red'>Please do not hesitate to drop me an email if you are interested in joining my lab. </font>
</li>
<li>
I will serve as an Area Chair for CVPR 2021.
</li>
<li>
Three papers accepted by CVPR 2020.
</li>
</ul>-->
<h2>Experiences</h2>

<ul>

<li>
Postdoctoral Researcher| <a href="http://www.robots.ox.ac.uk/~tvg/">Torr Vision Group</a>, University of Oxford, Oxford United Kingdom | Dec. 2018 – Jan. 2020</br>
Advisor: <a href="http://www.robots.ox.ac.uk/~phst/">Philip H. S. Torr</a></br>
</li>


 <li>
Research Intern | <a href="http://vladlen.info/lab/">Intel Visual Computing Lab</a>, Intel, Santa Clara, California, USA | May. 2017 – Nov. 2017</br>
Advisor: <a href="http://vladlen.info/">Vladlen Koltun</a></br>
Topic: Image Synthesis</br>
</li>

<li>
Visiting Student | <a href="http://www.cs.toronto.edu:40292/">Machine Learning Group</a>, University of Toronto, Toronto, Canada | Sep. 2016 – Dec . 2016</br>
Advisor: <a href="http://www.cs.toronto.edu/~urtasun/">Raquel Urtasun</a> & <a href="http://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a></br> 
Topic: RGBD Semantic Segmentation</br>
</li>

</ul>



<h2>Selected Publications [<a href="https://scholar.google.com/citations?hl=en&user=bGn0uacAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>]</h2>
*: equal contribution
   <ul>
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf">Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability
   </br></a>
   Ruifei He, Shuyang Sun*, Jihan Yang*, Song Bai, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/KDEP">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf">HINT: Hierarchical Neuron Concept Explainer
   </br></a>
    Andong Wang, Wei-Ning Lee, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/AntonotnaWang/HINT">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.pdf">Video Demoireing With Relation-Based Temporal Consistency
   </br></a>
    Peng Dai, Xin Yu, Lan Ma, Baoheng Zhang, Jia Li, Wenbo Li, Jiajun Shen, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/VideoDemoireing">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.pdf">Stratified Transformer for 3D Point Cloud Segmentation
   </br></a>
    Xin Lai*, Jianhui Liu*, Li Jiang, Liwei Wang, Hengshuang Zhao, Shu Liu, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/Stratified-Transformer">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


 <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.pdf">Towards Implicit Text-Guided 3D Shape Generation
   </br></a>
    Zhengzhe Liu, Yi Wang, <b>Xiaojuan Qi</b>, Chi-Wing Fu.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/liuzhengzhe/Towards-Implicit-Text-Guided-Shape-Generation">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.pdf">TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation
   </br></a>
    Ruihang Chu, Xiaoqing Ye, Zhengzhe Liu, Xiao Tan, <b>Xiaojuan Qi</b>, Chi-Wing Fu, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/TWIST">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf">Voxel Field Fusion for 3D Object Detection
   </br></a>
    Yanwei Li, <b>Xiaojuan Qi</b>, Yukang Chen, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/VFF">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf">Voxel Field Fusion for 3D Object Detection
   </br></a>
    Yanwei Li, <b>Xiaojuan Qi</b>, Yukang Chen, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/VFF">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.pdf">Slot-VPS: Object-Centric Representation Learning for Video Panoptic Segmentation
   </br></a>
    Yi Zhou, Hui Zhang, Hana Lee, Shuyang Sun, Pingjun Li, Yangguang Zhu, ByungIn Yoo, <b>Xiaojuan Qi</b>, Jae-Joon Han.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.pdf">Progressive End-to-End Object Detection in Crowded Scenes
   </br></a>
    Anlin Zheng, Yuang Zhang, Xiangyu Zhang, <b>Xiaojuan Qi</b>, Jian Sun.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/megvii-research/Iter-E2EDET">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

 <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/He_Re-Distributing_Biased_Pseudo_Labels_for_Semi-Supervised_Semantic_Segmentation_A_Baseline_ICCV_2021_paper.pdf">Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation
   </br></a>
    Ruifei He*, Jihan Yang*, <b>Xiaojuan Qi</b></br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021.</br>
    <b><font color = 'red'>Oral (3.4% acceptance rate) </font></b></br>
    [<a href="https://github.com/CVMI-Lab/DARS">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Sun_Aggregation_With_Feature_Detection_ICCV_2021_paper.html">Aggregation with Feature Detection
   </br></a>
    Shuyang Sun, Xiaoyu Yue, <b>Xiaojuan Qi</b>, Wanli Ouyang, Victor Prisacariu, Philip H.S. Torr</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_ST3D_Self-Training_for_Unsupervised_Domain_Adaptation_on_3D_Object_Detection_CVPR_2021_paper.html">ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection
   </br></a>
    Jihan Yang*, Shaoshuai Shi*, Zhe Wang, Hongsheng Li, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/CVMI-Lab/ST3D">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.pdf">PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds
   </br></a>
    Mutian Xu*, Runyu Ding*, Hengshuang Zhao, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/CVMI-Lab/PAConv">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.pdf">3D-to-2D Distillation for Indoor Scene Parsing
   </br></a>
    Zhengzhe Liu, <b>Xiaojuan Qi</b>, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    <b><font color = 'red'>Oral (4.3% acceptance rate) </font></b></br>
    [<a href="https://github.com/liuzhengzhe/3D-to-2D-Distillation-for-Indoor-Scene-Parsing">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.pdf">Fully Convolutional Networks for Panoptic Segmentation
   </br></a>
    Yanwei Li, Hengshuang Zhao, <b>Xiaojuan Qi</b>, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    <b><font color = 'red'>Oral (4.3% acceptance rate) </font></b></br>
    [<a href="https://github.com/Jia-Research-Lab/PanopticFCN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_One_Thing_One_Click_A_Self-Training_Approach_for_Weakly_Supervised_CVPR_2021_paper.pdf">One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation
   </br></a>
    Zhengzhe Liu, <b>Xiaojuan Qi</b>, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/liuzhengzhe/One-Thing-One-Click">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="https://papers.nips.cc/paper/2020/file/fae0b27c451c728867a567e8c1bb4e53-Paper.pdf">Lightweight Generative Adversarial Networks for Text-guided Image Manipulation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Philip H.S. Torr, Thomas Lukasiewicz.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9184024">GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation
   </br></a>
    <b> Xiaojuan Qi</b>*, Zhengzhe Liu*, Renjie Liao, Philip H. S. Torr, Raquel Urtasun, Jiaya Jia.</br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence  (<b>TPAMI</b>), 2020 (accepted).</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  	<li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470409.pdf">Domain-invariant Stereo Matching Networks
   </br></a>
    Feihu Zhang, <b> Xiaojuan Qi</b>, Ruigang Yang, Victor Adrian Prisacariu, Benjamin Wah, Philip H.S. Torr.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <b><font color = 'red'>Oral (2% acceptance rate)</font></b></br>
    [<a href="https://github.com/feihuzhang/DSMNet">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500511.pdf">Few-shot Action Recognition via Improved Attention with Self-supervision
   </br></a>
    Hongguang Zhang, Li Zhang, <b> Xiaojuan Qi</b>, Hongdong Li, Philip H.S. Torr, Piotr Koniusz.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <b><font color = 'red'>Spotlight (5% acceptance rate)</font></b>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550596.pdf">CN: Channel Normalization For Point Cloud
Recognition
   </br></a>
    Zetong Yang*, Yanan Sun*, Shu Liu, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600171.pdf">Memory Selection Network for
Video Propagation
   </br></a>
    Ruizheng Wu*, Huaijia Lin*, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="real_fake.pdf">Global Texture Enhancement for Fake Face Detection in the Wild
   </br></a>
    Zhengzhe Liu, <b> Xiaojuan Qi</b>, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://arxiv.org/abs/2001.04982">Unifying Training and Inference for Panoptic Segmentation
   </br></a>
    Qizhu Li, <b> Xiaojuan Qi</b>, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="https://arxiv.org/abs/1912.06203">ManiGAN: Text-Guided Image Manipulation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Thomas Lukasiewicz, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.</br>
     [<a href="https://github.com/mrlibw/ManiGAN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="https://arxiv.org/pdf/1909.07083.pdf">Controllable Text-to-Image Generation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Thomas Lukasiewicz, Philip H.S. Torr.</br>
     Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2019.</br>
     [<a href="https://github.com/mrlibw/ControlGAN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_AGSS-VOS_Attention_Guided_Single-Shot_Video_Object_Segmentation_ICCV_2019_paper.pdf">AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation
   </br></a>
    Huaijia Lin, <b> Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2019.</br>
    [<a href="https://github.com/Jia-Research-Lab/AGSS-VOS">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Improved_Techniques_for_Training_Adaptive_Deep_Networks_ICCV_2019_paper.pdf">Improved Techniques for Training Adaptive Deep Networks
   </br></a>
    Hao Li*, Hong Zhang*, <b> Xiaojuan Qi</b>, Ruigang Yang, Gao Huang.</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2019.
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="https://xjqi.github.io/motiondecomp.pdf">3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis
   </br></a>
    <b> Xiaojuan Qi*</b>, Zhengzhe Liu*, Qifeng Chen, Jiaya Jia.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2019.
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://papers.nips.cc/paper/7316-image-inpainting-via-generative-multi-column-convolutional-neural-networks.pdf">Image Inpainting via Generative Multi-column Convolutional Neural Networks
</br></a>
    Yi Wang, Xin Tao, <b> Xiaojuan Qi</b>, Xiaoyong Shen, Jiaya Jia.</br>
    Conference on Neural Information Processing Systems (<b>NIPS</b>), 2018. </br>
   [<a href="https://github.com/shepnerd/inpainting_gmcnn">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdf">ICNet for Real-Time Semantic Segmentation on High-Resolution Images</br></a>
    Hengshuang Zhao, <b> Xiaojuan Qi</b>, Xiaoyong Shen, Jianping Shi, Jiaya Jia</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2018. </br>
   [<a href="https://github.com/hszhao/ICNet">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Li_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.pdf">GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction</br></a>
    Li Jiang, Shaoshuai Shi, <b> Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2018. </br>
  <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="http://delivery.acm.org/10.1145/3250000/3240530/p145-liu.pdf?ip=129.67.95.205&id=3240530&acc=ACTIVE%20SERVICE&key=BF07A2EE685417C5%2EF2FAECDC86A918EB%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1547042293_ce3628fae4da448c78d961f9665d1cef">Self-Boosted Gesture Interactive System with ST-Net</br></a>
    Zhengzhe Liu*, <b> Xiaojuan Qi*</b>, Lei Pang.</br>
    ACM Multimedia Conference (<b>ACM MM</b>), 2018. </br> 
    <b><font color = 'red'>Full Research Paper</font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.pdf">GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation</br></a>
<b>Xiaojuan Qi</b>, Renjie Liao, Zhengzhe Liu, Raquel Urtasun, Jiaya Jia</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
<p style="margin-top:3px"></p>
  </li>

<li>
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.pdf">Semi-parametric Image Synthesis</br></a>
<b>Xiaojuan Qi</b>, Qifeng Chen, Jiaya Jia, Vladlen Koltun</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</br>
  <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b></br>
 [<a href="https://github.com/xjqicuhk/SIMS">Code</a>][<a href="https://youtu.be/U4Q98lenGLQ">Video</a>][<a href="https:/xjqi.github.io/sims-supplement.pdf">Supplement</a>]
<p style="margin-top:3px"></p>
  </li>

<li>
<a href="referseg.pdf">Referring Image Segmentation via Recurrent Refinement Networks </br></a>
Ruiyu Li, Kaican Li, Yi-Chun Kuo, Michelle Shu, <b>Xiaojuan Qi</b>, Xiaoyong Shen, Jiaya Jia.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</font></b>
<p style="margin-top:3px"></p>
  </li>

 
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf">3D Graph Neural Networks for RGBD Semantic Segmentation</br></a>
<b>Xiaojuan Qi</b>, Renjie Liao, Jiaya Jia, Sanja Fidler, Raquel Urtasun</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2017 </br>
    <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b></br>
    [<a href="https://github.com/xjqicuhk/3DGNN">Code</a>]</li>
<p style="margin-top:3px"></p>
  </li>

 
  <li>
    <a href="https://arxiv.org/pdf/1612.01105.pdf">Pyramid Scene Parsing Network</br></a>
    Hengshuang Zhao, Jianping Shi, <b>Xiaojuan Qi</b>, Xiaogang Wang, Jiaya Jia</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017.  </br>
    <b><font color = 'red'>Winner in ImageNet Scene Parsing Challenge 2016</font></b></br>
    [<a href="https://hszhao.github.io/projects/pspnet/index.html">Project & Code</a>]
    <p style="margin-top:3px">
    </p>      
  </li>

  <li>
    <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-46484-8_6.pdf">Augmented Feedback in Semantic Segmentation under Image Level Supervision</br></a>
    <b>Xiaojuan Qi</b>, Zhengzhe Liu, Jianping Shi, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2016. </br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780642">DCAN: Deep Contour-Aware Networks for Accurate Gland Segmentation</br></a>
    Hao Chen, <b>Xiaojuan Qi</b>, Lequan Yu , Pheng-Ann Heng.</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016.  </br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7780711">Multi-scale Patch Aggregation (MPA) for Simultaneous Detection and Segmentation</br></a>
    Shu Liu, <b>Xiaojuan Qi</b>, Jianping Shi,  Jiaya Jia</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016</br>
    <b><font color = 'red'>Oral (3.9% acceptance rate)</font></b></br>
    <p style="margin-top:3px">
    </p>
  </li>
  
  <li>
    <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11789/11718">Deep Contextual Networks for Neuronal Structure Segmentation</br></a>
    Hao Chen*, <b>Xiaojuan Qi</b>*, Jie-Zhi Cheng,  Pheng-Ann Heng.</br>
    Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), 2016</br>
    <b><font color = 'red'>Oral</font></b></br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7410654">Semantic Segmentation with Object Clique Potential</br></a>
    <b>Xiaojuan Qi</b>, Jianping Shi, Shu Liu, Renjie Liao, Jiaya Jia</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2015 </br>
    <p style="margin-top:3px"></p>
  </li>
</ul>

<h2>Honors and Awards</h2>
<ul>
 Full Oral presentations (acceptance rate about 2%-4%) at ECCV'18, CVPR'18, ICCV'17, CVPR'16, AAAI'16.</br>
 Outstanding Reviewer Award at ICCV 2019.</br>
 CVPR'18 Doctoral Consortium Travel Award.</br>
 Outstanding Reviewer Award at ICCV 2017.</br>
 Certificate of Merit for Best TA (Fall 2016 - 2017).</br>
 Hong Kong PhD Fellowship Award (200 candidates in Hong Kong), 2014 - 2018.</br>
 1st Place Winner at the ImageNet Scene Parsing Challenge, 2016.</br>
 1st Place Winner at MICCAI Gland Segmentation Challenge, 2015.</br>
 Excellent Graduate Award, Shanghai Jiao Tong University, 2014.</br>
 Excellent Student Scholarship, Shanghai Jiao Tong University, 2011 - 2013.</br>
 SCSK Corporation (Japan) Scholarship, 2013.</br>
 Pan Wenyuan (Tai Wan) Scholarship, 2011.</br>
</ul>

<h2>Professional Activities</h2>
<ul>

<li>Program Committees: </li>
 Area Chair for AAAI 2022. </br>
 Area Chair for ICCV 2021. </br>
 Area Chair for CVPR 2021. </br>
 Area Chair for AAAI 2021. </br>
 Senior Program Committee Member for AAAI 2020.</br>
<li>Conference Review: </li>
 European Conference on Computer Vision (ECCV) 2020.</br>
 Neural Information Systems Processing Conference (NIPS) 2020.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2020.</br>
 Internation Conference on Learning Representations (ICLR) 2020. </br>
 International Conference on Computer Vision (ICCV) 2019.</br>
 British Machine Vision Conference (BMVC) 2019.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2019.</br>
 International Joint Conference on Artificial Intelligence (IJCAI) 2019.</br>
 European Conference on Computer Vision (ECCV) 2018.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2018.</br>
 Neural Information Systems Processing Conference (NIPS) 2018.</br>
 Asian Conference on Computer Vision (ACCV) 2018.</br>
 International Joint Conference on Artificial Intelligence (IJCAI) 2018.</br>
 International Conference on Computer Vision (ICCV) 2017.</br>

<li>Journal Review:</li>

Nature Machine Intelligence. </br>
International Journal on Computer Vision (IJCV).</br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI).</br>
IEEE Transaction on Image Processing (TIP).</br>
IEEE Transaction on knowledge and Data Engineering (TKDE).</br>
ACM Transaction on Intelligent Systems and Technology (ACM TIST).</br>
Pattern Recognition (PR).</br>
Medical Image Analysis (MedIA).</br>
IEEE Transaction on Medical Imaging (TMI).</br>
</ul>
<h2>Teaching</h2>
<table id="Teaching" border="0" width="100%">
	<tbody>
		<tr>
			<td>CSCI 4190 Introduction to Social Networks</td><td>Fall</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>ENGG 5104 Image Processing and Computer Vision (Certificate of Merit for Best TA)</td><td>Fall</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>ENGG 2601A Technology, Society and Engineering Practice</td><td>Spring</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>CSCI 3290  Computational Photography</td><td>Fall</td><td>2015-2016</td>
		</tr>
		<tr>
			<td>ENGG 2120 Digital Logic and Systems</td><td>Fall</td><td>2014-2015</td>
		</tr>
	</tbody>
</table>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
