<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Xiaojuan Qi, University of Hong Kong"> 
<meta name="description" content="Xiaojuan Qi's home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xiaojuan Qi</title>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body >

<div id="layout-content" style="margin-top:25px">



<h2>Computer Vision and Machine Intelligence Lab (CVMI Lab)</h2>
<p>
	We are a group of people working on computer vision, deep learning and artificial intelligence. We aim to push forward visual intelligence toward open-world senarios. We are interested in the following topics: 
	<li>
	(1) Build real-world visual data simulation engines through 3D reconstruction and data generation. 
	</li>
	<li>
	(2) Develop interface between large vision and language foundation models for open-vocabulary understanding and intelligent reasoning.
	</li>
	<li>
	(3) Design reliable and trustworthy visual models with lifelong learning abilities .
	</li>
	<li>
	(4) Develop efficient training and inference algorithms for "green", sustainable and cost effective visual intelligence.  
	</li>
</p>
<font color = 'red'>Please drop us an email if you are interested in joining my lab. </font>
<p>
</p>

<h2>Lab Updates</h2>
<ul>
<li>
Dr. Xiaojuan Qi will be an area chair for NeurIPS 2023.
</li>
<li>
Seven papers are accepted to CVPR 2023. Congratulations to my students and collaborators.
</li>
<li>
Five papers are accepted to NeurIPS 2022. Congratulations to my students and collaborators. 
</li>
</ul>
	
<h2>Lab Members</h2>



<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
