<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Xiaojuan Qi, University of Hong Kong"> 
<meta name="description" content="Xiaojuan Qi's home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xiaojuan Qi</title>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body >

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Xiaojuan Qi &nbsp; <h1>
				</div>
                            
				<h3>Assistant Professor</h3>
				<p>
					Chow Yei Ching Building, Rm 518 </br>
					Dept. of Electrical and Electronic Engineering</br>
					University of Hong Kong </br>
					 Hong Kong</br>
					</br>
					Email: <a href="mailto:xjqi@eee.hku.hk">xjqi [at] eee.hku.hk</a><br> 
                                    <h3> <a href="https://scholar.google.com/citations?hl=en&user=bGn0uacAAAAJ&view_op=list_works&sortby=pubdate">[Google Scholar]</a> <a href="https://xjqi.github.io/cvmi.html">[CVMI Lab]</a><a href="https://github.com/CVMI-Lab">[Lab GitHub]</a><h3>
				</p>
				
			</td>
			<td>
				<img src="pics/me.jpg" border="0" width="240"></br>
			</td>
		<tr>
	</tbody>
</table>


<h2>Biography</h2>
<p>
I am currently an assistant professor at <a href="https://www.hku.hk/">the University of Hong Kong</a> and a member of <a href="https://www.dvlab.ai/">Deep Vision Lab</a>. My research encompasses the broad areas of Computer Vision, Deep Learning, and Artificial Intelligence. My objective is to equip machines with open-world capabilities for perceiving, understanding, and reconstructing the visual world, focusing on the following aspects: 1) 3D reconstruction, generation, and visual environment simulation; 2) Open-world, interactive and reliable visual understanding; 3) Efficient training and inference; 4) Applications on open-ended intelligent agents (e.g., autonomous driving, embodied agents). Besides, I am also interested in utilizing AI to advance scientific and medical research (AI for Science and Medicine).
</p>
I obtained my Ph.D. degree in <a href="http://www.cse.cuhk.edu.hk">Computer Science and Engineering Department</a>, <a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong (CUHK)</a>, supervised by <a href="http://www.cse.cuhk.edu.hk/~leojia">Prof. Jiaya Jia</a> in 2018. Before that, I got the B.Eng. degree in Electronic Science and Technology at <a href = "http://www.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a> supervised by <a href="http://ir.sjtu.edu.cn/~yazhang/">Prof. Ya Zhang</a> in 2014.
<p>
</p>
<font color = 'red'>Please email me if you are interested in joining my lab. We have one Postdoc opening in vision for robotics. Please contact me if you are interested in this opportunity. </font>
<p>
</p>
<!--
<h2>Recent Updates</h2>
<ul>
<li>
<font color = 'red'>Please drop me an email if you are interested in joining my lab. I might be slow in replying to emails in October </font>
</li>
<li>
I will serve as an Area Chair for CVPR 2021.
</li>
<li>
Three papers accepted by CVPR 2020.
</li>
</ul>-->
<h2>Experiences</h2>

<ul>

<li>
Postdoctoral Researcher| <a href="http://www.robots.ox.ac.uk/~tvg/">Torr Vision Group</a>, University of Oxford, Oxford United Kingdom | Dec. 2018 – Jan. 2020</br>
Advisor: <a href="http://www.robots.ox.ac.uk/~phst/">Philip H. S. Torr</a></br>
</li>


 <li>
Research Intern | <a href="http://vladlen.info/lab/">Intel Visual Computing Lab</a>, Intel, Santa Clara, California, USA | May. 2017 – Nov. 2017</br>
Advisor: <a href="http://vladlen.info/">Vladlen Koltun</a></br>
Topic: Image Synthesis</br>
</li>

<li>
Visiting Student | <a href="http://www.cs.toronto.edu:40292/">Machine Learning Group</a>, University of Toronto, Toronto, Canada | Sep. 2016 – Dec . 2016</br>
Advisor: <a href="http://www.cs.toronto.edu/~urtasun/">Raquel Urtasun</a> & <a href="http://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a></br> 
Topic: RGBD Semantic Segmentation</br>
</li>

</ul>

<h2>Selected Publications [<a href="https://scholar.google.com/citations?hl=en&user=bGn0uacAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>]</h2>
*: equal contribution, #: corresponding author
   <ul>
   <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/10551628/"> Lowis3d: Language-driven open-world instance-level 3d scene understanding
   </br></a>
    Runyu Ding, Jihan Yang, Chuhui Xue, Wenqing Zhang, Song Bai, <b>Xiaojuan Qi#</b>.</br>
     IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/PLA">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://www.nature.com/articles/s41467-024-49125-z">Diffusion-based deep learning method for augmenting ultrastructural imaging and volume electron microscopy
   </br></a>
    Chixiang Lu, Kai Chen, Heng Qiu, Xiaojun Chen, Gu Chen, <b>Xiaojuan Qi#</b>, Haibo Jiang#</br>
     Nature Communications, 2024.</br>
    [<a href="https://github.com/Luchixiang/EMDiffuse">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
 <li>
    <a href="https://pubs.acs.org/doi/abs/10.1021/jacs.4c05384">Tool to Resolve Distortions in Elemental and Isotopic Imaging
   </br></a>
    Chixiang Lu, Gu Chen, Wenxin Song, Kai Chen, Charmaine Hee, Mehran Nikan, Paul Guagliardo, C Frank Bennett, Punit Seth, Killugudi Swaminathan Iyer, Stephen G Young, <b>Xiaojuan Qi#</b>, Haibo Jiang#</br>
    Journal of the American Chemical Society (<b>JACS</b>), 2024.</br>
    [<a href="https://www.haibojianglab.com/nanosims-stabilizer">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://www.researchsquare.com/article/rs-3164142/v1">High-dimensional anticounterfeiting nanodiamonds authenticated with deep metric learning
   </br></a>
    Lingzhi Wang*, Xin Yu*, Tongtong Zhang, Yong Hou, Dangyuan Lei, <b>Xiaojuan Qi#</b>, Zhiqin Chu#. </br>
     Nature Communications, 2024 (Accepted with Minor Revision).</br>
    [<a href="https://github.com/CVMI-Lab/PLA">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01023.pdf">Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models
   </br></a>
    Chuofan Ma, Yi Jiang, Jiannan Wu, Zehuan Yuan, <b>Xiaojuan Qi</b>.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.</br>
    [<a href="https://groma-mllm.github.io/">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01889.pdf">Can OOD Object Detectors Learn from Foundation Models?
   </br></a>
    Jiahui Liu, Xin Wen, Shizhen Zhao, Yingxian Chen, <b>Xiaojuan Qi</b>.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/SyncOOD">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06117.pdf">V-IRL: Grounding Virtual Intelligence in Real Life </br></a>
   Jihan Yang, Runyu Ding, Ellis L Brown, <b>Xiaojuan Qi</b>, Saining Xie.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.</br>
    [<a href="https://virl-platform.github.io/">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/12305.pdf">3D-Aware Text-Driven Talking Avatar Generation </br></a>
    Xiuzhe Wu, Yang-Tian Sun, Handi Chen, Hang Zhou, Jingdong Wang, Zhengzhe Liu, <b>Xiaojuan Qi</b>.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
 <li>
    <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00698.pdf">UniDream: Unifying Diffusion Priors for Relightable Text-to-3D Generation</br></a>
   Zexiang Liu, Yangguang Li, Youtian Lin, Xin Yu, Sida Peng, Yan-Pei Cao, <b>Xiaojuan Qi</b>, Xiaoshui Huang, Ding Liang*, Wanli Ouyang.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2024.</br>
    [<a href="https://yg256li.github.io/UniDream/">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://arxiv.org/abs/2405.21070">What Makes CLIP More Robust to Long-Tailed Pre-Training Data? A Controlled Study for Transferable Insights</br></a>
    Xin Wen, Bingchen Zhao, Yilun Chen, Jiangmiao Pang, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/clip-beyond-tail">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://openreview.net/pdf?id=bzuQtVDxv0">Splatter a Video: Video Gaussian Representation for Versatile Processing
   </br></a>
    Yang-Tian Sun*, Yi-Hua Huang*, Lin Ma, Xiaoyang Lyu, Yan-Pei Cao, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</br>
    [<a href="https://sunyangtian.github.io/spatter_a_video_web/">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://arxiv.org/abs/2405.21070">Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting</br></a>
    Ziyi Yang, Xinyu Gao, Yangtian Sun, Yihua Huang, Xiaoyang Lyu, Wen Zhou, Shaohui Jiao, <b>Xiaojuan Qi</b>, Xiaogang Jin</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</br>
    [<a href="https://ingra14m.github.io/Spec-Gaussian-website/">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://openreview.net/pdf?id=SfunjRKld1">Decoupled Kullback-Leibler (DKL) Divergence Loss</br></a>
    Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, <b>Xiaojuan Qi</b>, Bei Yu, Hanwang Zhang.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.</br>
    [<a href="https://github.com/jiequancui/DKL">Project Page</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/10531009">Object-centric Representation Learning for Video Scene Understanding
   </br></a>
    Yi Zhou, Hui Zhang, Seung-In Park, ByungIn Yoo, <b>Xiaojuan Qi#</b>.</br>
     IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2024.</br>
    [<a href="https://github.com/liuzhengzhe/DreamStone-ISS">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://arxiv.org/pdf/2402.04291">BiLLM: Pushing the Limit of Post-Training Quantization for LLMs</br></a>
    Wei Huang, Yangdong Liu, Haotong Qin, Ying Li, Shiming Zhang, Xianglong Liu, Michele Magno, <b>Xiaojuan Qi</b>. </br>
    International Conference on Machine Learning (<b>ICML</b>), 2024.</br>
    [<a href="https://github.com/Aaronhuang-778/BiLLM">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="TEXGen_TOG.pdf">TEXGen: a Generative Diffusion Model for Mesh Textures
   </br></a>
   Xin Yu, Ze Yuan, Yuan-Chen Guo, Ying-Tian Liu, Jianhui Liu, Yangguang Li, Yan-Pei Cao, Ding Liang <b>Xiaojuan Qi#</b>.</br>
    SIGGRAPH Asia (journal track), 2024. </br>
    [<a href="https://github.com/CVMI-Lab">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="3DGSR_Sig_Asia.pdf">3DGSR: Implicit Surface Reconstruction with 3D Gaussian Splatting
   </br></a>
   Xiaoyang Lyu, Yang-Tian Sun, Yi-Hua Huang, Xiuzhe Wu, Ziyi Yang, Yilun Chen, Jiangmiao Pang, <b>Xiaojuan Qi#</b>.</br>
    SIGGRAPH Asia (journal track), 2024. </br>
    [<a href="https://github.com/CVMI-Lab">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
     <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Lyu_Total-Decom_Decomposed_3D_Scene_Reconstruction_with_Minimal_Interaction_CVPR_2024_paper.pdf">Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction
   </br></a>
    Xiaoyang Lyu*, Chirui CHANG*, Peng Dai, Yang-Tian_Sun, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/Total-Decom">Code</a>]. </br>
      <b><font color = 'red'>Highlight (3.6% acceptance rate) </font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
     <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_RegionPLC_Regional_Point-Language_Contrastive_Learning_for_Open-World_3D_Scene_Understanding_CVPR_2024_paper.pdf">RegionPLC: Regional Point-Language Contrastive Learning for Open-World 3D
Scene Understanding
   </br></a>
    Jihan Yang, Runyu Ding, Weipeng DENG, Zhe Wang, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/PLA">Code</a>][<a href="https://jihanyang.github.io/projects/RegionPLC">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
     <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Huang_SC-GS_Sparse-Controlled_Gaussian_Splatting_for_Editable_Dynamic_Scenes_CVPR_2024_paper.pdf">SC-GS: Sparse-Controlled Gaussian Splatting for Editable Dynamic Scenes
   </br></a>
    Yi-Hua Huang, Yang-Tian Sun, Ziyi Yang, Xiaoyang Lyu, Yan-Pei Cao, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://github.com/yihua7/SC-GS">Code</a>][<a href="https://yihua7.github.io/SC-GS-web/">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Kong_EscherNet_A_Generative_Model_for_Scalable_View_Synthesis_CVPR_2024_paper.pdf">EscherNet: A Generative Model for Scalable View Synthesis </br></a>
    Xin Kong, Shikun Liu, Xiaoyang Lyu, Marwan Taher, <b>Xiaojuan Qi</b>, Andrew Davison. </br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://kxhit.github.io/EscherNet">Project Page</a>]. </br>
     <b><font color = 'red'>Oral (0.8% acceptance rate) </font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wu_SaCo_Loss_Sample-wise_Affinity_Consistency_for_Vision-Language_Pre-training_CVPR_2024_paper.pdf">SaCo Loss: Sample-wise Affinity Consistency for Vision-Language Pre-training</br></a>
    Sitong Wu, Haoru Tan, Zhuotao Tian, Yukang Chen, <b>Xiaojuan Qi</b>, Jiaya Jia. </br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://github.com/dvlab-research/SaCo-Loss">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Cui_Classes_Are_Not_Equal_An_Empirical_Study_on_Image_Recognition_CVPR_2024_paper.pdf">Classes Are Not Equal: An Empirical Study on Image Recognition Fairness </br></a>
    Jiequan Cui, Beier Zhu, Xin Wen, <b>Xiaojuan Qi</b>, Bei Yu, Hanwang Zhang. </br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2024.</br>
    [<a href="https://github.com/dvlab-research/SaCo-Loss">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openreview.net/pdf?id=ktG8Tun1Cy">Text-to-3d with classifier score distillation
   </br></a>
    Xin Yu, Yuan-Chen Guo, Yangguang Li, Ding Liang, Song-Hai Zhang,<b>Xiaojuan Qi</b>.</br>
    International Conference on Learning Representations (<b>ICLR</b>), 2024.</br>
    [<a href="https://github.com/CVMI-Lab/Classifier-Score-Distillation">Code</a>][<a href="https://xinyu-andy.github.io/Classifier-Score-Distillation/">Project Page</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openreview.net/pdf?id=TKjX41IP7n">CoDet: Co-occurrence Guided Region-Word Alignment for Open-Vocabulary Object Detection
   </br></a>
   Chuofan Ma, Yi Jiang, Xin Wen, Zehuan Yuan, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/CoDet">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    <li>
    <a href="https://openreview.net/pdf?id=vO6ZdPWaHc">Data Pruning via Moving-one-Sample-out
   </br></a>
   Haoru Tan, Sitong Wu, Fei Du, Yukang Chen, Zhibin Wang, Fan Wang, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2023.</br>
    [<a href="https://github.com/hrtan/MoSo">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://openreview.net/pdf?id=uZjpSBTPik">CL-NeRF: Continual Learning of Neural Radiance Fields for Evolving Scene Representation
   </br></a>
   Xiuzhe Wu, Peng Dai, Weipeng DENG, Handi Chen, Yang Wu, Yan-Pei Cao, Ying Shan, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://dl.acm.org/doi/10.1145/3618312">EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape Generation
   </br></a>
   Zhengzhe Liu, Jingyu Hu, Ka-Hei Hui, <b>Xiaojuan Qi#</b>, Daniel Cohen-Or, Chi-Wing Fu#.</br>
    SIGGRAPH Asia (journal track), 2023. </br>
    [<a href="https://github.com/liuzhengzhe/EXIM">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/10269027/">DreamStone: Image as a Stepping Stone for Text-Guided 3D Shape Generation
   </br></a>
    Zhengzhe Liu, Peng Dai, <b>Xiaojuan Qi#</b>, Chi-Wing Fu#.</br>
     IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023.</br>
    [<a href="https://github.com/liuzhengzhe/DreamStone-ISS">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/10262344">Vertical Layering of Quantized Neural Networks for Heterogeneous Inference
   </br></a>
    Hai Wu, Ruifei He, Haoru Tan, <b>Xiaojuan Qi</b>, Kaibin Huang#.</br>
     IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2023.</br>
    [<a href="https://github.com/liuzhengzhe/DreamStone-ISS">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
   <li>
    <a href="https://arxiv.org/pdf/2211.11727.pdf">Parametric Classification for Generalized Category Discovery: A Baseline Study
   </br></a>
    Xin Wen*, Bingchen Zhao*, <b>Xiaojuan Qi</b>.</br>
     IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/SimGCD">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://arxiv.org/pdf/2308.10490.pdf">Texture Generation on 3D Meshes with Point-UV Diffusion
   </br></a>
    Xin Yu, Peng Dai, Wenbo Li, Lan Ma, Zhengzhe Liu, <b>Xiaojuan Qi</b>.</br>
     IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023.</br>
    [<a href="https://cvmi-lab.github.io/Point-UV-Diffusion/">Code</a>]. </br>
    <b><font color = 'red'>Oral (2.4 % acceptance rate) </font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>  
   <li>
    <a href="https://arxiv.org/pdf/2303.13479">Prior-free Category-level Pose Estimation with Implicit Space Transformation
   </br></a>
    Jianhui Liu, Yukang Chen, Xiaoqing Ye, <b>Xiaojuan Qi</b>.</br>
     IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/IST-Net/">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  </li> 
   <li>
    <a href="https://arxiv.org/pdf/2303.09152">Learning a Room with the Occ-SDF Hybrid: Signed Distance Function Mingled with Occupancy Aids Scene Representation
   </br></a>
    Xiaoyang Lyu, Peng Dai, Zizhang Li, Dongyu Yan, Yi Lin, Yifan Peng, <b>Xiaojuan Qi</b>.</br>
     IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/IST-Net/">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://arxiv.org/pdf/2309.04814.pdf">Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video
   </br></a>
   Xiuzhe Wu, Pengfei Hu, Yang Wu, Xiaoyang Lyu, Yan-Pei Cao, Ying Shan, Wenming Yang, Zhongqian Sun, <b>Xiaojuan Qi</b>.</br>
     IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/Speech2Lip">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Ding_PLA_Language-Driven_Open-Vocabulary_3D_Scene_Understanding_CVPR_2023_paper.html">PLA: Language-Driven Open-Vocabulary 3D Scene Understanding
   </br></a>
    Runyu Ding, Jihan Yang, Chuhui Xue, Wenqing Zhang, Song Bai, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://dingry.github.io/projects/PLA">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Dai_Hybrid_Neural_Rendering_for_Large-Scale_Scenes_With_Motion_Blur_CVPR_2023_paper.pdf">Hybrid Neural Rendering for Large-Scale Scenes with Motion Blur
   </br></a>
    Peng Dai*, Yinda Zhang*, Xin Yu, Xiaoyang Lyu, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/HybridNeuralRendering">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Liu_MarS3D_A_Plug-and-Play_Motion-Aware_Model_for_Semantic_Segmentation_on_Multi-Scan_CVPR_2023_paper.html">MarS3D: A Plug-and-Play Motion-Aware Model for Semantic Segmentation on Multi-Scan 3D Point Clouds
   </br></a>
    Jiahui Liu*, Chirui Chang*, Jianhui Liu, Xiaoyang Wu, Lan Ma, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/CVMI-Lab/HybridNeuralRendering">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_LargeKernel3D_Scaling_Up_Kernels_in_3D_Sparse_CNNs_CVPR_2023_paper.pdf">LargeKernel3D: Scaling Up Kernels in 3D Sparse CNNs 
    </br></a>
    Yukang Chen*, Jianhui Liu*, Xiangyu Zhang, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/dvlab-research/LargeKernel3D">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_VoxelNeXt_Fully_Sparse_VoxelNet_for_3D_Object_Detection_and_Tracking_CVPR_2023_paper.pdf">VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking
    </br></a>
    Yukang Chen*, Jianhui Liu*, Xiangyu Zhang, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/dvlab-research/VoxelNeXt">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chu_Command-Driven_Articulated_Object_Understanding_and_Manipulation_CVPR_2023_paper.pdf">Command-Driven Articulated Object Understanding and Manipulation
    </br></a>
    Ruihang Chu, Zhengzhe Liu, Xiaoqing Ye, Xiao Tan, <b>Xiaojuan Qi</b>, Chi-Wing Fu, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/dvlab-research/Cart">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
 <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhong_Understanding_Imbalanced_Semantic_Segmentation_Through_Neural_Collapse_CVPR_2023_paper.pdf">Understanding Imbalanced Semantic Segmentation Through Neural Collapse
   </br></a>
    Zhisheng Zhong*, Jiequan Cui*, Yibo Yang*, Xiaoyang Wu, <b>Xiaojuan Qi</b>, Xiangyu Zhang, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2023.</br>
    [<a href="https://github.com/dvlab-research/Imbalanced-Learning">Code</a>]. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
 <li>
    <a href="https://dl.acm.org/doi/abs/10.1145/3575693.3575728">DPACS: Hardware Accelerated Dynamic Neural Network Pruning through Algorithm-Architecture Co-design
   </br></a>
    Yizhao Gao*, Baoheng Zhang*, <b>Xiaojuan Qi</b>, Hayden Kwok-Hay So.</br>
    Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (<b>ASPLOS</b>), 2023.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  <li>
    <a href="https://arxiv.org/abs/2210.07574">Is synthetic data from generative models ready for image recognition?
   </br></a>
    Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, <b>Xiaojuan Qi</b>.</br>
    International Conference on Learning Representations (<b>ICLR</b>, 2023.</br>
    [<a href="https://github.com/CVMI-Lab/SyntheticData">Code</a>]. </br>
     <b><font color = 'red'>Spotlight</font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
  <li>
    <a href="https://arxiv.org/abs/2209.04145">ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation
   </br></a>
    Zhengzhe Liu, Peng Dai, Ruihui Li, <b>Xiaojuan Qi</b>, Chi-Wing Fu.</br>
    International Conference on Learning Representations (<b>ICLR</b>), 2023.</br>
    [<a href="https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation">Code</a>][<a href="https://liuzhengzhe.github.io/ISS.github.io/">Project Page</a>]. </br>
    <b><font color = 'red'>Spotlight</font></b></br>
   <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://ieeexplore.ieee.org/document/9927350">St3d++: Denoised self-training for unsupervised domain adaptation on 3d object detection
   </br></a>
    Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, <b>Xiaojuan Qi#</b>.</br>
   IEEE Transactions on Pattern Analysis & Machine Intelligence (<b>TPAMI</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/ST3D">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://openreview.net/pdf?id=H3JObxjd8S">Self-Supervised Visual Representation Learning with Semantic Grouping
   </br></a>
    Xin Wen, Bingchen Zhao, Anlin Zheng, Xiangyu Zhang, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/SlotCon">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
 <li>
    <a href="https://openreview.net/pdf?id=1tnVNogPUz9">Towards Efficient 3D Object Detection with Knowledge Distillation
   </br></a>
     Jihan Yang, Shaoshuai Shi, Runyu Ding, Zhe Wang, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/SparseKD">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
   </li> 
   <li>
    <a href="https://openreview.net/pdf?id=kCTZt0b9DQz">Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection
   </br></a>
    Shizhen Zhao, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/FS3D">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openreview.net/pdf?id=rnJzy8JnaX">Rethinking Resolution in the Context of Efficient Video Recognition
   </br></a>
   Chuofan Ma, Qiushan Guo, Yi Jiang, Ping Luo, Zehuan Yuan, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/ResKD">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
   <li>
    <a href="https://openreview.net/pdf?id=QqWqFLbllZh">Spatial Pruned Sparse Convolution for Efficient 3D Object Detection
   </br></a>
   Jianhui Liu*, Yukang Chen*, Xiaoqing Ye, Zhuotao Tian, Xiao Tan, <b>Xiaojuan Qi</b>.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/SPS-Conv">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li> 
    <li>
    <a href="https://openreview.net/forum?id=XA4ru9mfxTP">Unifying Voxel-based Representation with Transformer for 3D Object Detection
   </br></a>
   Yanwei Li, Yilun Chen, <b>Xiaojuan Qi</b>, Zeming Li, Jian Sun, Jiaya Jia.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/UVTR">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>   
	   
    <li>
    <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870280.pdf">DODA: Data-oriented Sim-to-Real Domain Adaptation for 3D Semantic Segmentation
   </br></a>
     Runyu Ding*, Jihan Yang*, Li Jiang, <b>Xiaojuan Qi</b>.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/DODA">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    <li>
    <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136780634.pdf">Towards Efficient and Scale-Robust Ultra-High-Definition Image Demoireing
   </br></a>
    Xin Yu, Peng Dai, Wenbo Li, Lan Ma, Jiajun Shen, Jia Li, <b>Xiaojuan Qi</b>.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/UHDM">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf">Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability
   </br></a>
   Ruifei He, Shuyang Sun*, Jihan Yang*, Song Bai, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/KDEP">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf">HINT: Hierarchical Neuron Concept Explainer
   </br></a>
    Andong Wang, Wei-Ning Lee, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/AntonotnaWang/HINT">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.pdf">Video Demoireing With Relation-Based Temporal Consistency
   </br></a>
    Peng Dai, Xin Yu, Lan Ma, Baoheng Zhang, Jia Li, Wenbo Li, Jiajun Shen, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/CVMI-Lab/VideoDemoireing">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf">Voxel Field Fusion for 3D Object Detection
   </br></a>
    Yanwei Li, <b>Xiaojuan Qi</b>, Yukang Chen, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/VFF">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.pdf">Stratified Transformer for 3D Point Cloud Segmentation
   </br></a>
    Xin Lai*, Jianhui Liu*, Li Jiang, Liwei Wang, Hengshuang Zhao, Shu Liu, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/Stratified-Transformer">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


 <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.pdf">Towards Implicit Text-Guided 3D Shape Generation
   </br></a>
    Zhengzhe Liu, Yi Wang, <b>Xiaojuan Qi</b>, Chi-Wing Fu.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/liuzhengzhe/Towards-Implicit-Text-Guided-Shape-Generation">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.pdf">Slot-VPS: Object-Centric Representation Learning for Video Panoptic Segmentation
   </br></a>
    Yi Zhou, Hui Zhang, Hana Lee, Shuyang Sun, Pingjun Li, Yangguang Zhu, ByungIn Yoo, <b>Xiaojuan Qi</b>, Jae-Joon Han.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.pdf">TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation
   </br></a>
    Ruihang Chu, Xiaoqing Ye, Zhengzhe Liu, Xiao Tan, <b>Xiaojuan Qi</b>, Chi-Wing Fu, Jiaya Jia.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/dvlab-research/TWIST">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.pdf">Progressive End-to-End Object Detection in Crowded Scenes
   </br></a>
    Anlin Zheng, Yuang Zhang, Xiangyu Zhang, <b>Xiaojuan Qi</b>, Jian Sun.</br>
    IEEE Conference on Computer Vision and Pattern Recognition  (<b>CVPR</b>), 2022.</br>
    [<a href="https://github.com/megvii-research/Iter-E2EDET">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

 <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/He_Re-Distributing_Biased_Pseudo_Labels_for_Semi-Supervised_Semantic_Segmentation_A_Baseline_ICCV_2021_paper.pdf">Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation
   </br></a>
    Ruifei He*, Jihan Yang*, <b>Xiaojuan Qi</b></br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021.</br>
    <b><font color = 'red'>Oral (3.4% acceptance rate) </font></b></br>
    [<a href="https://github.com/CVMI-Lab/DARS">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Sun_Aggregation_With_Feature_Detection_ICCV_2021_paper.html">Aggregation with Feature Detection
   </br></a>
    Shuyang Sun, Xiaoyu Yue, <b>Xiaojuan Qi</b>, Wanli Ouyang, Victor Prisacariu, Philip H.S. Torr</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021. </br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
    
    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_ST3D_Self-Training_for_Unsupervised_Domain_Adaptation_on_3D_Object_Detection_CVPR_2021_paper.html">ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection
   </br></a>
    Jihan Yang*, Shaoshuai Shi*, Zhe Wang, Hongsheng Li, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/CVMI-Lab/ST3D">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.pdf">PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds
   </br></a>
    Mutian Xu*, Runyu Ding*, Hengshuang Zhao, <b>Xiaojuan Qi</b>.</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/CVMI-Lab/PAConv">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.pdf">3D-to-2D Distillation for Indoor Scene Parsing
   </br></a>
    Zhengzhe Liu, <b>Xiaojuan Qi</b>, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    <b><font color = 'red'>Oral (4.3% acceptance rate) </font></b></br>
    [<a href="https://github.com/liuzhengzhe/3D-to-2D-Distillation-for-Indoor-Scene-Parsing">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  
  <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.pdf">Fully Convolutional Networks for Panoptic Segmentation
   </br></a>
    Yanwei Li, Hengshuang Zhao, <b>Xiaojuan Qi</b>, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    <b><font color = 'red'>Oral (4.3% acceptance rate) </font></b></br>
    [<a href="https://github.com/Jia-Research-Lab/PanopticFCN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_One_Thing_One_Click_A_Self-Training_Approach_for_Weakly_Supervised_CVPR_2021_paper.pdf">One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation
   </br></a>
    Zhengzhe Liu, <b>Xiaojuan Qi</b>, Chi-Wing Fu</br>
    IEEE Conference on Computer Vision and pattern Recognition  (<b>CVPR</b>), 2021.</br>
    [<a href="https://github.com/liuzhengzhe/One-Thing-One-Click">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="https://papers.nips.cc/paper/2020/file/fae0b27c451c728867a567e8c1bb4e53-Paper.pdf">Lightweight Generative Adversarial Networks for Text-guided Image Manipulation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Philip H.S. Torr, Thomas Lukasiewicz.</br>
    Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="https://ieeexplore.ieee.org/abstract/document/9184024">GeoNet++: Iterative Geometric Neural Network with Edge-Aware Refinement for Joint Depth and Surface Normal Estimation
   </br></a>
    <b> Xiaojuan Qi</b>*, Zhengzhe Liu*, Renjie Liao, Philip H. S. Torr, Raquel Urtasun, Jiaya Jia.</br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence  (<b>TPAMI</b>), 2020.</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  	<li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123470409.pdf">Domain-invariant Stereo Matching Networks
   </br></a>
    Feihu Zhang, <b> Xiaojuan Qi</b>, Ruigang Yang, Victor Adrian Prisacariu, Benjamin Wah, Philip H.S. Torr.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <b><font color = 'red'>Oral (2% acceptance rate)</font></b></br>
    [<a href="https://github.com/feihuzhang/DSMNet">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500511.pdf">Few-shot Action Recognition via Improved Attention with Self-supervision
   </br></a>
    Hongguang Zhang, Li Zhang, <b> Xiaojuan Qi</b>, Hongdong Li, Philip H.S. Torr, Piotr Koniusz.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <b><font color = 'red'>Spotlight (5% acceptance rate)</font></b>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550596.pdf">CN: Channel Normalization For Point Cloud
Recognition
   </br></a>
    Zetong Yang*, Yanan Sun*, Shu Liu, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123600171.pdf">Memory Selection Network for
Video Propagation
   </br></a>
    Ruizheng Wu*, Huaijia Lin*, <b>Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2020.</br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

    <li>
    <a href="real_fake.pdf">Global Texture Enhancement for Fake Face Detection in the Wild
   </br></a>
    Zhengzhe Liu, <b> Xiaojuan Qi</b>, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.</br>
    [<a href="https://github.com/liuzhengzhe/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="https://arxiv.org/abs/2001.04982">Unifying Training and Inference for Panoptic Segmentation
   </br></a>
    Qizhu Li, <b> Xiaojuan Qi</b>, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="https://arxiv.org/abs/1912.06203">ManiGAN: Text-Guided Image Manipulation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Thomas Lukasiewicz, Philip H.S. Torr.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2020.</br>
     [<a href="https://github.com/mrlibw/ManiGAN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="https://arxiv.org/pdf/1909.07083.pdf">Controllable Text-to-Image Generation
   </br></a>
    Bowen Li, <b> Xiaojuan Qi</b>, Thomas Lukasiewicz, Philip H.S. Torr.</br>
     Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2019.</br>
     [<a href="https://github.com/mrlibw/ControlGAN">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

   <li>
    <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_AGSS-VOS_Attention_Guided_Single-Shot_Video_Object_Segmentation_ICCV_2019_paper.pdf">AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation
   </br></a>
    Huaijia Lin, <b> Xiaojuan Qi</b>, Jiaya Jia.</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2019.</br>
    [<a href="https://github.com/Jia-Research-Lab/AGSS-VOS">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Improved_Techniques_for_Training_Adaptive_Deep_Networks_ICCV_2019_paper.pdf">Improved Techniques for Training Adaptive Deep Networks
   </br></a>
    Hao Li*, Hong Zhang*, <b> Xiaojuan Qi</b>, Ruigang Yang, Gao Huang.</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2019.
    <p style="margin-top:3px"></p>  
    </p>
  </li>


   <li>
    <a href="https://xjqi.github.io/motiondecomp.pdf">3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis
   </br></a>
    <b> Xiaojuan Qi*</b>, Zhengzhe Liu*, Qifeng Chen, Jiaya Jia.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition (<b>CVPR</b>), 2019.
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="https://papers.nips.cc/paper/7316-image-inpainting-via-generative-multi-column-convolutional-neural-networks.pdf">Image Inpainting via Generative Multi-column Convolutional Neural Networks
</br></a>
    Yi Wang, Xin Tao, <b> Xiaojuan Qi</b>, Xiaoyong Shen, Jiaya Jia.</br>
    Conference on Neural Information Processing Systems (<b>NIPS</b>), 2018. </br>
   [<a href="https://github.com/shepnerd/inpainting_gmcnn">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdf">ICNet for Real-Time Semantic Segmentation on High-Resolution Images</br></a>
    Hengshuang Zhao, <b> Xiaojuan Qi</b>, Xiaoyong Shen, Jianping Shi, Jiaya Jia</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2018. </br>
   [<a href="https://github.com/hszhao/ICNet">Code</a>]
    <p style="margin-top:3px"></p>  
    </p>
  </li>

  <li>
    <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Li_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.pdf">GAL: Geometric Adversarial Loss for Single-View 3D-Object Reconstruction</br></a>
    Li Jiang, Shaoshuai Shi, <b> Xiaojuan Qi</b>, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2018. </br>
  <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b>
    <p style="margin-top:3px"></p>  
    </p>
  </li>
  <li>
    <a href="http://delivery.acm.org/10.1145/3250000/3240530/p145-liu.pdf?ip=129.67.95.205&id=3240530&acc=ACTIVE%20SERVICE&key=BF07A2EE685417C5%2EF2FAECDC86A918EB%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1547042293_ce3628fae4da448c78d961f9665d1cef">Self-Boosted Gesture Interactive System with ST-Net</br></a>
    Zhengzhe Liu*, <b> Xiaojuan Qi*</b>, Lei Pang.</br>
    ACM Multimedia Conference (<b>ACM MM</b>), 2018. </br> 
    <b><font color = 'red'>Full Research Paper</font></b></br>
    <p style="margin-top:3px"></p>  
    </p>
  </li>

<li>
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.pdf">GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation</br></a>
<b>Xiaojuan Qi</b>, Renjie Liao, Zhengzhe Liu, Raquel Urtasun, Jiaya Jia</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</br>
    [<a href="https://github.com/xjqi/GeoNet">Code</a>][<a href="https://hkuhk-my.sharepoint.com/:f:/g/personal/xjqi_hku_hk/Ek0Vm--5oi1GssioLE5LjO0ByLTKpWAG00zYYUCeiydR7g?e=8kAdLZ">Training data</a>]
<p style="margin-top:3px"></p>
  </li>

<li>
<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.pdf">Semi-parametric Image Synthesis</br></a>
<b>Xiaojuan Qi</b>, Qifeng Chen, Jiaya Jia, Vladlen Koltun</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</br>
  <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b></br>
 [<a href="https://github.com/xjqicuhk/SIMS">Code</a>][<a href="https://youtu.be/U4Q98lenGLQ">Video</a>][<a href="https:/xjqi.github.io/sims-supplement.pdf">Supplement</a>]
<p style="margin-top:3px"></p>
  </li>

<li>
<a href="referseg.pdf">Referring Image Segmentation via Recurrent Refinement Networks </br></a>
Ruiyu Li, Kaican Li, Yi-Chun Kuo, Michelle Shu, <b>Xiaojuan Qi</b>, Xiaoyong Shen, Jiaya Jia.</br>
    IEEE Conference on Computer Vision  and Pattern Recognition(<b>CVPR</b>), 2018.</font></b>
<p style="margin-top:3px"></p>
  </li>

 
<li>
<a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qi_3D_Graph_Neural_ICCV_2017_paper.pdf">3D Graph Neural Networks for RGBD Semantic Segmentation</br></a>
<b>Xiaojuan Qi</b>, Renjie Liao, Jiaya Jia, Sanja Fidler, Raquel Urtasun</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2017 </br>
    <b><font color = 'red'>Oral (2.1% acceptance rate)</font></b></br>
    [<a href="https://github.com/xjqicuhk/3DGNN">Code</a>]</li>
<p style="margin-top:3px"></p>
  </li>

 
  <li>
    <a href="https://arxiv.org/pdf/1612.01105.pdf">Pyramid Scene Parsing Network</br></a>
    Hengshuang Zhao, Jianping Shi, <b>Xiaojuan Qi</b>, Xiaogang Wang, Jiaya Jia</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017.  </br>
    <b><font color = 'red'>Winner in ImageNet Scene Parsing Challenge 2016</font></b></br>
    [<a href="https://hszhao.github.io/projects/pspnet/index.html">Project & Code</a>]
    <p style="margin-top:3px">
    </p>      
  </li>

  <li>
    <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-46484-8_6.pdf">Augmented Feedback in Semantic Segmentation under Image Level Supervision</br></a>
    <b>Xiaojuan Qi</b>, Zhengzhe Liu, Jianping Shi, Jiaya Jia.</br>
    European Conference on Computer Vision (<b>ECCV</b>), 2016. </br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780642">DCAN: Deep Contour-Aware Networks for Accurate Gland Segmentation</br></a>
    Hao Chen, <b>Xiaojuan Qi</b>, Lequan Yu , Pheng-Ann Heng.</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016.  </br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7780711">Multi-scale Patch Aggregation (MPA) for Simultaneous Detection and Segmentation</br></a>
    Shu Liu, <b>Xiaojuan Qi</b>, Jianping Shi,  Jiaya Jia</br>
    IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016</br>
    <b><font color = 'red'>Oral (3.9% acceptance rate)</font></b></br>
    <p style="margin-top:3px">
    </p>
  </li>
  
  <li>
    <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11789/11718">Deep Contextual Networks for Neuronal Structure Segmentation</br></a>
    Hao Chen*, <b>Xiaojuan Qi</b>*, Jie-Zhi Cheng,  Pheng-Ann Heng.</br>
    Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), 2016</br>
    <b><font color = 'red'>Oral</font></b></br>
    <p style="margin-top:3px">
    </p>
  </li>

  <li>
    <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7410654">Semantic Segmentation with Object Clique Potential</br></a>
    <b>Xiaojuan Qi</b>, Jianping Shi, Shu Liu, Renjie Liao, Jiaya Jia</br>
    IEEE International Conference on Computer Vision (<b>ICCV</b>), 2015 </br>
    <p style="margin-top:3px"></p>
  </li>
</ul>

<h2>Honors and Awards</h2>
<ul>
 Full Oral presentations (acceptance rate about 2%-4%) at ECCV'18, CVPR'18, ICCV'17, CVPR'16, AAAI'16.</br>
 Outstanding Reviewer Award at ICCV 2019.</br>
 CVPR'18 Doctoral Consortium Travel Award.</br>
 Outstanding Reviewer Award at ICCV 2017.</br>
 Certificate of Merit for Best TA (Fall 2016 - 2017).</br>
 Hong Kong PhD Fellowship Award (200 candidates in Hong Kong), 2014 - 2018.</br>
 1st Place Winner at the ImageNet Scene Parsing Challenge, 2016.</br>
 1st Place Winner at MICCAI Gland Segmentation Challenge, 2015.</br>
</ul>

<h2>Professional Activities</h2>
<ul>

<li>Program Committees: </li>
 Area Chair for NeurIPS 2023. </br>
 Area Chair for CVPR 2023. </br>
 Area Chair for WACV 2023. </br>
 Senior Program Committee Member for AAAI 2023.</br>
 Area Chair for AAAI 2022. </br>
 Area Chair for ICCV 2021. </br>
 Area Chair for CVPR 2021. </br>
 Area Chair for AAAI 2021. </br>
 Senior Program Committee Member for AAAI 2020.</br>
<li>Conference Review: </li>
 European Conference on Computer Vision (ECCV) 2020.</br>
 Neural Information Systems Processing Conference (NIPS) 2020.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2020.</br>
 Internation Conference on Learning Representations (ICLR) 2020. </br>
 International Conference on Computer Vision (ICCV) 2019.</br>
 British Machine Vision Conference (BMVC) 2019.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2019.</br>
 International Joint Conference on Artificial Intelligence (IJCAI) 2019.</br>
 European Conference on Computer Vision (ECCV) 2018.</br>
 International Conference on Computer Vision and Pattern Recognition (CVPR) 2018.</br>
 Neural Information Systems Processing Conference (NIPS) 2018.</br>
 Asian Conference on Computer Vision (ACCV) 2018.</br>
 International Joint Conference on Artificial Intelligence (IJCAI) 2018.</br>
 International Conference on Computer Vision (ICCV) 2017.</br>

<li>Journal Review:</li>

Nature Machine Intelligence. </br>
International Journal on Computer Vision (IJCV).</br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI).</br>
IEEE Transaction on Image Processing (TIP).</br>
IEEE Transaction on knowledge and Data Engineering (TKDE).</br>
ACM Transaction on Intelligent Systems and Technology (ACM TIST).</br>
Pattern Recognition (PR).</br>
Medical Image Analysis (MedIA).</br>
IEEE Transaction on Medical Imaging (TMI).</br>
</ul>
<h2>Teaching</h2>
<table id="Teaching" border="0" width="100%">
	<tbody>
		<tr>
			<td>CSCI 4190 Introduction to Social Networks</td><td>Fall</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>ENGG 5104 Image Processing and Computer Vision (Certificate of Merit for Best TA)</td><td>Fall</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>ENGG 2601A Technology, Society and Engineering Practice</td><td>Spring</td><td>2016-2017</td>
		</tr>
		<tr>
			<td>CSCI 3290  Computational Photography</td><td>Fall</td><td>2015-2016</td>
		</tr>
		<tr>
			<td>ENGG 2120 Digital Logic and Systems</td><td>Fall</td><td>2014-2015</td>
		</tr>
	</tbody>
</table>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88615920-1', 'auto');
  ga('send', 'pageview');

</script>

</div>
</body>
</html>
